{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d6jfHlQkMSb_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"sentiment_analysis.csv\")"
      ],
      "metadata": {
        "id": "6r3FTAixx5BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "AdEzhQCOP7IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "E7JbMbC1P5IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ipOE0VEEQHb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "import re"
      ],
      "metadata": {
        "id": "spAXwUC0QKXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Q_durOQPxc",
        "outputId": "56a40b91-f848-4555-d751-61c7ad6f6484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw=nltk.corpus.stopwords.words(\"english\")\n",
        "sw[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LLzfkqfQTsx",
        "outputId": "095b00a9-b64e-400c-ba2d-f293c20f5bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps=nltk.PorterStemmer()"
      ],
      "metadata": {
        "id": "8qwLNmKmQdl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleantext(txt):\n",
        "  lst1=\"\".join([i for i in txt if i not in string.punctuation])\n",
        "  lst2=re.split('\\W+',txt)\n",
        "  lst3=[i for i in lst2 if i not in sw]\n",
        "  lst4=[ps.stem(i) for i in lst3]\n",
        "  return lst4\n",
        "df[\"clean\"]=df[\"text\"].apply(lambda x : cleantext(x))\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "SsizMA1-QpeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.DataFrame(df[\"clean\"])\n",
        "x.head()"
      ],
      "metadata": {
        "id": "WoDnG88oRcal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=pd.DataFrame(df[\"label\"])\n",
        "y.head()"
      ],
      "metadata": {
        "id": "wgknLPXyRmNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "Z0wC0UaW7asv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "tLprevuA8BP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "tq2blOpA8F3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train[\"clean\"])\n",
        "x_train_seq=tokenizer.texts_to_sequences(x_train[\"clean\"])\n",
        "x_test_seq=tokenizer.texts_to_sequences(x_test[\"clean\"])"
      ],
      "metadata": {
        "id": "75EP26_i8Q8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_seq_padded=pad_sequences(x_train_seq,50)\n",
        "x_test_seq_padded=pad_sequences(x_test_seq,50)"
      ],
      "metadata": {
        "id": "OM93c-7t8o29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense,Embedding,LSTM\n",
        "from keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "qIV22wzh83bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sq=Sequential()\n",
        "model_sq.add(Embedding(len(tokenizer.index_word)+1,32))\n",
        "model_sq.add(LSTM(32,dropout=0,recurrent_dropout=0))\n",
        "model_sq.add(Dense(32,activation='relu'))\n",
        "model_sq.add(Dense(1,activation='sigmoid'))\n",
        "model_sq.summary()"
      ],
      "metadata": {
        "id": "wkpBzYkV9Cje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model_sq.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KoiI02my9_zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the RNN model\n",
        "model_sq.fit(x_train_seq_padded,y_train['label'],batch_size=32,epochs=5,validation_data=(x_test_seq_padded,y_test))"
      ],
      "metadata": {
        "id": "Z7izzy9m-Ngt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"Hi there, I hope you are doing good! Take care and love\""
      ],
      "metadata": {
        "id": "e4fAvrKr-i1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata=pd.DataFrame({\"text\":[s]})\n",
        "newdata"
      ],
      "metadata": {
        "id": "WZEaHrR6-sA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata[\"clean\"]=newdata[\"text\"].apply(lambda x:cleantext(x))\n",
        "newdata.head()"
      ],
      "metadata": {
        "id": "uQkJKcX6-yrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(newdata[\"clean\"])\n",
        "x=tokenizer.texts_to_sequences(newdata[\"clean\"])"
      ],
      "metadata": {
        "id": "aj8bJrS4-_Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_padded=pad_sequences(x,50)"
      ],
      "metadata": {
        "id": "qxVH06Lm_KpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sq.predict(x_padded)"
      ],
      "metadata": {
        "id": "R_I9xMr4_OZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sq.save(\"sentiment.h5\",save_format='h5')"
      ],
      "metadata": {
        "id": "M--h_irE_SLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load=tensorflow.keras.models.load_model(\"sentiment.h5\")"
      ],
      "metadata": {
        "id": "8EAYaLdy_aov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load.predict(x_padded)"
      ],
      "metadata": {
        "id": "59uiPW0u_h6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}